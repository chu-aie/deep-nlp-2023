# 시대를 따르는 오타 수정 시스템 

**Project Title**
- 시대를 따르는 오타 수정 시스템

_Prepared by: 김지연_

1. 김지연 202021013

## Table of Contents

- [Project Title](#project-title)
  - [Table of Contents](#table-of-contents)
  - [1. Executive Summary](#1-executive-summary)
  - [2. Background](#2-background)
  - [3. Objectives](#3-objectives)
  - [4. Scope](#4-scope)
  - [5. Software Process Model](#5-software-process-model)
  - [6. Budget](#6-budget)
  - [7. System Architecture](#7-system-architecture)
  - [8. Risks Assessment](#8-risks-assessment)
  - [9. Resources](#9-resources)
  - [10. Technical Specifications](#10-technical-specifications)
  - [11. Timeline and Deliverables](#11-timeline-and-deliverables)
  - [12. Conclusion](#12-conclusion)


## 1. Executive Summary

- 시대를 따르는 오타 수정 시스템의 주요 목표는 현재 트랜드에 적응하여 오타를 감지하고 수정하는 능력을 가진 AI 시스템을 개발하는 것으로 이를 통해 시대에 따라 언어와 텍스트 스타일이 변화하는 문제를 해결하고 올바른 정보 전달을 지원하여 사용자 경험을 개선하고자 합니다.

## 2. Background

- 현대 사회에서 텍스트는 중요한 의사소통 도구이며, 온라인 플랫폼과 소셜 미디어의 보급으로 텍스트 사용량이 폭증했습니다. 기존의 오타 교정 시스템은 과거 데이터에 의존하여 현대 언어와 문체에 부적응을 초래할 수 있습니다. 따라서 현대 텍스트의 품질을 향상시키기 위해, 현대 언어와 문체에 대응하는 오타 교정 시스템을 개발하고자 합니다. 이로써 올바른 정보 전달과 소통의 효율성을 높이며 사용자 경험을 향상시키며 현대의 급격한 언어 변화와 텍스트 사용량 증가에 대응하기 위해 선택되었습니다.

## 3. Objectives

- 2023년 12월 10일 까지 LLM 모델을 활용 하여 2000년 대 초반과 현재의 유행어와 신조어를 고려한 오타 수정 시스템을 개발 하여 2000년대 초반과 현재를 비교하여 프로젝트를 진행할 것입니다. 오타 수정 시스템의 정확도를 측정하여 2000년대 초반과 현재의 텍스트에서 발견된 오타의 수를 비교합니다. LLM 모델을 활용하여 오타 수정 시스템을 개발하기 위해 필요한 인력 및 컴퓨팅 자원을 확보합니다. 또한, 이 프로젝트는 딥러닝 자연어처리 과목과 밀접한 관련이 있어, 해당 과목의 학습과 실무 경험을 향상시키는데 기여할 것으로 예상됩니다.

## 4. Scope

*주요 특징 및 기능:*
1. 다양한 데이터 소스 지원 : 2000년대 초반과 현재의 유행어와 신조어를 포함한 다양한 데이터 소스(예: 싸이월드, YouTube 채널, Instagram 댓글 등)에서 데이터 수집 및 분석 기능을 제공합니다.

2. 자연어 처리(NLP) 모델 : LLM(Large Language Model)과 같은 최신 NLP 모델을 활용하여 오타와 맞춤법 오류를 감지하고 수정하는 기능을 수행합니다.

3. 유행어와 신조어 대응 : 신조어와 유행어의 빠른 변화에 대응하기 위해 실시간 데이터 수집 및 모델 업데이트 기능을 제공합니다.

*제약 및 제한:*
1. 프로젝트 일정: 12월 말까지 제한된 시간 내에 프로젝트를 완료하는 일정을 준수해야합니다.

2. 데이터 수집 제약: 2000년대 초반 데이터의 한정적인 접근성 및 현재의 데이터는 실시간으로 크롤링되어야 해 정확하고 많은 데이터 수집이 어려울 수 있습니다.


## 5. Software Process Model

V 모델은 소프트웨어 개발 및 품질 관리 단계를 나타내는 대칭적인 모델로, 개발과 품질 보증 단계가 대칭되어 연결되어 있습니다.

1. 요구사항 분석 (Requirements Analysis):

    2010년 이전의 인터넷 플랫폼(싸이월드)에서 크롤링한 데이터와 유튜브 채널 및 댓글 데이터를 수집하여 당시의 맞춤법 오류 및 오타 패턴을 파악하고, 현재의 유튜브와 인스타그램 댓글 데이터를 크롤링하여 이를 오타 수정 시스템에 적용하여 신조어와 유행어를 오타가 아닌 올바른 단어로 자동으로 수정하도록 하는 것을 목표로 합니다.

2. 시스템 설계 (System Design):
    
    -데이터 수집과 분석:
    2010년 데이터 수집: 2010년 이전의 인터넷(싸이월드) 크롤링 및 유튜브 채널 및 댓글 데이터를 수집하여 당시의 맞춤법 오류 및 오타 패턴을 파악합니다.
    현재 데이터 수집 : 유튜브 댓글과 인스타 게시물 및 댓글을 크롤링을 통해 데이터를 수집합니다.
    수집한 데이터를 자연어 처리 및 텍스트 분석 기술을 사용하여 토픽 모델링, 언어 패턴 인식, 형태소 분석 등을 통해 유행어와 신조어를 식별하고 분류합니다.
    
    -데이터 전처리:
    수집한 데이터를 정제하고 표준화 합니다. 중복 데이터나 불필요한 정보를 제거하고, 텍스트를 토큰화 하여 처리 가능한 형태로 변환합니다.
    토큰화, 불용어 제거, 형태소 분석을 진행합니다. 형태소 분석과 같은 언어 처리 기술을 사용하여 텍스트를 분해하고, 언어 특성을 고려하여 텍스트를 정규화 합니다.
    
    -유행어 및 신조어 식별:
    소셜 미디어 플랫폼에서 빈번하게 사용되는 특정 어휘나 해시태그를 감지하고, 이를 유행어로 분류합니다.
    
3. 모델 통합 및 개발 (Model Integration and Development):

    LLM 모델을 개발하고 학습시킵니다. 이 모델은 과거와 현재의 언어 트렌드를 반영하도록 훈련되어야 합니다.
    신조어 및 유행어 감지 및 수정 알고리즘을 개발하고 모델과 통합합니다.
    네이버 맞춤법 검사기 라이브러리 py-hanspell을 참고하고자 합니다. - https://github.com/ssut/py-hanspell

4. 테스트 계획 (Test Planning):

    각 시대별 데이터와 시스템에 대한 테스트 계획을 수립합니다. 과거와 현재의 언어 트렌드에 따라 테스트 데이터를 선정합니다.

5. 단위 테스트 (Unit Testing):

    각 시대별로 개발한 모델과 시스템의 단위 테스트를 진행하여 정확성을 확인합니다.

6. 통합 및 시스템 테스트 (Integration and System Testing):
    
    각 시대별로 시스템의 통합 테스트를 수행하고, 오타 수정 및 유행어 감지 기능이 요구사항을 충족하는지 확인합니다.

7. 검증 및 확인 (Verification and Validation):

    검증 단계에서는 시스템이 요구사항을 충족하는지 검증합니다. 확인 단계에서는 사용자의 요구사항을 검토하고 피드백을 수용하여 개선합니다.

8. 운영 및 유지보수 (Operations and Maintenance):

    오타 수정 시스템을 운영하며, 주기적인 유지보수 및 업데이트를 수행합니다. 신조어 및 유행어의 변화를 계속 모니터링하고 시스템을 업데이트하여 최신 유행어에 대응합니다.

간트 차트:
- 데이터 수집: 4주
- 데이터 전처리 및 분석: 2주
- 모델 개발: 2주
- 시스템 구현: 2주
- 테스트트 및 오류 수정: 6주
- 사용자 피드백 및 모델 업데이트 계획: 1주

## 6. Budget

학교 서버 활용 계획입니다.

## 7. System Architecture

1. 데이터 수집 및 전처리:
   - 데이터 소스: 인터넷 컨텐츠, 유튜브 채널, 인스타그램 댓글
   - 데이터 크롤링: 웹 크롤링 도구 (예: Scrapy)
   - 데이터 전처리: 토큰화, 불용어 제거, 형태소 분석

2. NLP 모델 개발:
   - 딥러닝 NLP 모델: LLM (Large Language Model) 사용
   - 프로그래밍 언어: Python
   - 라이브러리: TensorFlow 또는 PyTorch

3. 네이버 맞춤법 검사기(py-hanspell) 활용:

    - Python 라이브러리인 `py-hanspell`을 사용하여 텍스트 데이터의 오타 및 맞춤법 오류를 검사하고 수정합니다.
    - `py-hanspell` 라이브러리는 네이버 맞춤법 검사기의 API를 활용하여 오타 및 맞춤법 오류를 식별합니다.
    - 각 문장을 `py-hanspell`로 전달하고, 오류가 발견되면 수정된 결과를 받아옵니다.

4. 수정된 데이터 저장:

    - 수정된 데이터를 기존의 JSON 또는 CSV 파일에 업데이트하거나, 새로운 파일로 저장합니다.

5. 데이터 시각화 및 분석 도구:
   - 데이터 시각화: Matplotlib, Seaborn, Tableau
   - 데이터 분석: Jupyter Notebook, Pandas, Numpy

6. 예외 처리:
    - `py-hanspell`을 사용할 때, API 호출이 실패하는 경우를 대비하여 예외 처리를 구현합니다.
    - 재시도 또는 오류 로깅과 같은 대처 방법을 고려합니다.

## 8. Risks Assessment

- 데이터 부족: 2000년대 초의 데이터 양이 한정적일 수 있음
    - 완화 전략: 데이터 증식 및 데이터 강화 기술을 사용하여 학습 데이터를 보강합니다.
- 유행어와 신조어 변화: 현재 유행어와 신조어가 빠르게 변하므로 시스템이 이에 대응하기 어려울 수 있음
    - 완화 전략: 실시간 크롤링을 통해 최신 데이터를 수집하고 모델을 주기적으로 업데이트합니다.
- 보안 문제: 개인 정보가 포함된 데이터를 다룰 경우, 데이터 보안 문제 발생 가능성
    - 완화 전략: 데이터 암호화, 접근 제어 및 규정 준수를 위한 보안 프로토콜을 구현하여 데이터 보안을 강화합니다.

## 9. Resources

- 장비: 학교 서버
- 소프트웨어: Python, TensorFlow 또는 PyTorch (딥러닝 모델 개발), 웹 크롤링 도구 (Scrapy)

## 10. Technical Specifications

- 데이터 원본: 2000년대 초와 현재의 웹 콘텐츠, 유튜브 채널 및 댓글, 인스타그램 댓글 데이터
- 데이터 변환: 텍스트 데이터의 토큰화, 불용어 제거, 형태소 분석
- 알고리즘: 딥러닝 모델 (예: LSTM, Transformer)을 사용한 NLP 모델
- 기술 스택: Python, TensorFlow 또는 PyTorch, Scrapy

## 11. Timeline and Deliverables

- 6주 : 학습 데이터 수집 및 전처리 완료
- 3주 : NLP 모델 개발 및 테스트 완료
- 2주 : 시스템 구현 및 테스트 완료
- 6주 : 테스트 및 오류 수정
- 1주 : 사용자 피드백 및 모델 업데이트 계획

## 12. Conclusion

- 이 프로젝트는 데이터 수집의 어려움을 예상하지만, 크롤링을 통해 다양한 소스에서 데이터를 수집하는 데 가능성이 있다고 판단합니다.
- 제한된 시간 내에 프로젝트를 완료해야 하므로 초기에는 부족한 점이 있을 것으로 예상되지만, 정확한 시스템을 초기에 구현하면 그 후에는 수정이 수월하게 이루어질 것으로 기대합니다.

요즘에는 신조어와 유행어가 연일 생겨나고 있지만, 대부분의 오타 검사기는 이러한 새로운 언어 트렌드를 제대로 인식하지 못하는 경향이 있습니다. 이로 인해 매년 등장하는 새로운 표현들을 정확하게 감지하고, 오타가 아닌 신조어로 인식하여 올바른 정보 전달과 효율적인 소통을 도모하며, 사용자 경험을 향상시키기 위한 시스템을 개발하고자 합니다. 이를 통해 현대의 급격한 언어 변화와 증가하는 텍스트 사용량에 효과적으로 대응할 수 있을 것입니다.
